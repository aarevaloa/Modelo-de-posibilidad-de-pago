# -*- coding: utf-8 -*-
"""
Created on Wed Jan 28 15:29:44 2026

@author: Andr茅s Felipe Ar茅valo Ar茅valo
"""
#_________________________________________________________________________________________________________________________
# Modulos
#_________________________________________________________________________________________________________________________
import pandas as pd
import numpy as np
from pathlib import Path
import statsmodels.api as sm
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix
from sklearn.metrics import f1_score, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
#_________________________________________________________________________________________________________________________
# Importando datos
#_________________________________________________________________________________________________________________________
# IMPORTANTE: Cambiese el objeto 'ruta', coloquese la ruta donde se almaceno la carpeta 'Ar茅valo_Andr茅s - Prueba_T茅cnica - Casa_Cobranzas_Beta' <----------------------
ruta = Path(r'C:\Users\USUARIO\Desktop\Main\Pruebas de conocimiento\Davivienda - Cobranzas Betas\Ar茅valo_Andr茅s - Prueba_T茅cnica - Casa_Cobranzas_Beta')
df_evolucion_enriquecida = pd.read_csv(ruta /'Resultados/df_evolucion_enriquecida.txt',sep='|', encoding='utf-8')

#_________________________________________________________________________________________________________________________
# Consideraciones preliminares
#_________________________________________________________________________________________________________________________
'''Pregunta objetivo: 驴Es probable que el cliente realice al menos un pago?
    - Variable objetivo binaria.
    - Observaci贸n a nivel cliente.
    - Problema de clasificaci贸n binaria. 
  Con base en lo anterior, primero hay que definir que se consider como 'realizar un pago', para esto hare uso de la variable 'TOTAL_PAGOS_APROBADOS' mayor
  a cero para construir una variable binaria, donde 1 es el cliente realiz贸 al menos un pago y 0 el cliente no realiz贸 ningun pago.'''

df_evolucion_enriquecida['PAGO_REALIZA'] = (df_evolucion_enriquecida['TOTAL_PAGOS_APROBADOS'] > 0).astype(int)

''' Inicialmente, la base de datos se encuentra estructurada a nivel de obligaci贸n y no a nivel de cliente. Dado que el objetivo del an谩lisis es determinar si un
    individuo realiza al menos un pago, se unifico la informaci贸n a nivel de la persona. En el proceso de selecci贸n de variables, se excluyeron aquellas que no 
    una relaci贸n l贸gica con la intenci贸n de pago, tales como identificadores y n煤meros de tel茅fono. Asimismo, se descartaron variables definidas a nivel de 
    obligaci贸n que resultan redundantes una vez consolidada la informaci贸n por cliente, como los saldos de capital individuales y los d铆as de mora por obligaci贸n. 
    Adicionalmente, la variable producto no fue incluida directamente en el modelo a nivel de individuo, dado que un mismo cliente puede estar asociado a m煤ltiples
    productos. Para incorporar esta informaci贸n ser铆a necesario realizar una clasificaci贸n previa de los productos en macrocategor铆as. Sin embargo, considerando 
    que ya se dispone de la variable TIPO_CLIENTE, se opt贸 por utilizarla como una aproximaci贸n de la complejidad financiera y la diversidad de productos del 
    individuo.'''

vars_modelo = [
    'SALDO_TOTAL_CLIENTE',
    'RANGO_MORA_CLIENTE',
    'TIPO_CLIENTE',
    'ESTADO_ORIGEN']

df_cliente = (
    df_evolucion_enriquecida
    .groupby('IDENTIFICACION')
    .agg(
        PAGO_REALIZA=('PAGO_REALIZA', 'max'),
        SALDO_TOTAL_CLIENTE=('SALDO_TOTAL_CLIENTE', 'first'),
        DIAS_MORA=('Dias Mora', 'max'),  
        RANGO_MORA_CLIENTE=('RANGO_MORA_CLIENTE', 'first'),
        TIPO_CLIENTE=('TIPO_CLIENTE', 'first'),
        ESTADO_ORIGEN=('ESTADO_ORIGEN', 'first')).reset_index())

#_________________________________________________________________________________________________________________________
# Analisis descriptivo
#_________________________________________________________________________________________________________________________
df_cliente['PAGO_REALIZA'].value_counts(normalize=True)

''' Se evidencia que m谩s del 83 % de los registros corresponden a personas que no realizaron ning煤n pago y que m谩s del 87 % de los individuos presentan m谩s de 540
    d铆as de mora. En consecuencia, el problema se encuentra altamente desbalanceado, por lo que m茅tricas como el accuracy y el uso de un umbral de clasificaci贸n 
    fijo de 0.5 no resultan apropiados para la evaluaci贸n del modelo.'''
    
prob_condicional_pago_dado_mora = pd.crosstab(df_cliente['RANGO_MORA_CLIENTE'], df_cliente['PAGO_REALIZA'], normalize='index')

''' El c贸digo de la l铆nea 74 calcula la probabilidad condicional de que un cliente realice al menos un pago dado su rango de mora. En particular, los valores 
    a la categor铆a 'MS DE 540' indican que un cliente con una mora superior a 540 d铆as realiza un pago 煤nicamente en el 16.6 % de los casos. La relaci贸n entre
    pago y mora presenta un comportamiento particular, ya que los clientes con mora extrema exhiben una probabilidad de pago superior a la observada en clientes 
    con moras intermedias. Este patr贸n puede explicarse por la existencia de procesos especiales de cobranza o acuerdos de pago aplicados a clientes con mora
    elevada, mientras que aquellos con moras intermedias tienden a postergar los pagos. En consecuencia, la relaci贸n entre mora y probabilidad de pago no es lineal,
    por lo que un modelo lineal simple resultar铆a ineficaz para capturar adecuadamente esta din谩mica.'''

prob_condicional_pago_dado_tipo_cliente = pd.crosstab(df_cliente['TIPO_CLIENTE'], df_cliente['PAGO_REALIZA'], normalize='index')

''' Al igual que en el caso anterior, se observa que los clientes multiproducto presentan una probabilidad de pago superior a la de los clientes monoproducto, 
    siendo esta m谩s del doble. Este resultado sugiere que, a medida que los clientes poseen un mayor n煤mero de productos, su relaci贸n con la entidad se fortalece,
    lo que genera mayores incentivos para mantenerse al d铆a con sus obligaciones financieras.'''

prob_condicional_pago_dado_estado = pd.crosstab(df_cliente['ESTADO_ORIGEN'], df_cliente['PAGO_REALIZA'], normalize='index')

''' No se observa una diferencia relevante entre los grupos analizados: tener un acuerdo registrado no modifica, en promedio, la probabilidad de que un cliente 
    realice al menos un pago. En consecuencia, esta variable no discrimina adecuadamente entre clientes pagadores y no pagadores y no parece aportar informaci贸n
    explicativa significativa. Por lo tanto, se excluye inicialmente del modelo y su eventual incorporaci贸n se evaluar谩 posteriormente en funci贸n de la mejora que
    pueda generar en el ajuste del modelo.'''
    
#_________________________________________________________________________________________________________________________
# Preparaci贸n de datos para modelar
#_________________________________________________________________________________________________________________________

''' En este bloque se prepara la base de datos para la estimaci贸n de un modelo de probabilidad de pago a nivel cliente. Inicialmente, se parte de una copia del 
    DataFrame consolidado y se eliminan observaciones con valores faltantes en las variables clave de saldo, mora y tipo de cliente, garantizando consistencia 
    en la muestra de modelaci贸n. Posteriormente, se construyen transformaciones y variables derivadas con el objetivo de capturar relaciones no lineales y efectos
    de interacci贸n relevantes desde el punto de vista econ贸mico, tales como transformaciones logar铆tmicas de saldo y d铆as de mora, razones e interacciones entre
    saldo y mora, e indicadores binarios de mora extrema y saldos altos. Luego, las variables categ贸ricas se convierten a formato num茅rico mediante dummys. 
    Con el conjunto de variables explicativas definido, los datos se dividen en muestras de entrenamiento y prueba de forma estratificada
    para preservar el desbalance de la variable objetivo. Finalmente, las variables se estandarizan para asegurar comparabilidad de escalas, se incorpora el 
    intercepto para mantener la integridad del espacio columna de la matriz de dise帽o y se calculan ponderaciones para la muestra de entrenamiento, con el fin de
    corregir el desbalance entre individuos que pagan y no pagan durante la estimaci贸n.'''
    
df_modelo = df_cliente.copy()
df_modelo = df_modelo.dropna(subset=['SALDO_TOTAL_CLIENTE', 'DIAS_MORA', 'TIPO_CLIENTE'])

df_modelo['LOG_SALDO'] = np.log1p(df_modelo['SALDO_TOTAL_CLIENTE']) # Para capturar relacione no lineales
df_modelo['LOG_DIAS_MORA'] = np.log1p(df_modelo['DIAS_MORA']) # Identificara clientes de alta deuda pero poca mora
df_modelo['RATIO_SALDO_MORA'] = df_modelo['SALDO_TOTAL_CLIENTE'] / (df_modelo['DIAS_MORA'] + 1) 
df_modelo['SALDO_X_MORA'] = df_modelo['SALDO_TOTAL_CLIENTE'] * df_modelo['DIAS_MORA'] # Evaluar interacci贸n entre saldos y mora
df_modelo['LOG_SALDO_X_MORA'] = np.log1p(df_modelo['SALDO_X_MORA'])
df_modelo['MORA_EXTREMA'] = (df_modelo['DIAS_MORA'] > 540).astype(int)
df_modelo['SALDO_ALTO'] = (df_modelo['SALDO_TOTAL_CLIENTE'] > df_modelo['SALDO_TOTAL_CLIENTE'].median()).astype(int)

df_modelo = pd.get_dummies(df_modelo, columns=['TIPO_CLIENTE'], drop_first=True, dtype=float)
vars_modelo = [
    'LOG_SALDO',
    'LOG_DIAS_MORA',
    'RATIO_SALDO_MORA',
    'LOG_SALDO_X_MORA',
    'MORA_EXTREMA',
    'SALDO_ALTO'] + [col for col in df_modelo.columns if col.startswith('TIPO_CLIENTE_')]

X = df_modelo[vars_modelo].copy()
y = df_modelo['PAGO_REALIZA'].copy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
scaler = StandardScaler()
X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns,index=X_train.index)
X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)
X_train_scaled = sm.add_constant(X_train_scaled)
X_test_scaled = sm.add_constant(X_test_scaled)

freq_train = y_train.value_counts(normalize=True)
weights_train = y_train.map({0: 1/freq_train[0], 1: 1/freq_train[1]})

#_________________________________________________________________________________________________________________________
# Ajuste del modelo probit
#_________________________________________________________________________________________________________________________
''' Se ajusta el modelo utilizando la muestra de entrenamiento, incorporando ponderaciones por observaci贸n con el fin de mitigar el desbalance existente entre 
    clientes pagadores y no pagadores, y permitiendo un mayor n煤mero de iteraciones para asegurar la convergencia del algoritmo de m谩xima verosimilitud. 
    Subsecuentemente, se presenta el resumen estad铆stico del modelo, que incluye los coeficientes estimados, su significancia y m茅tricas globales de ajuste. 
    Finalmente, el modelo se utiliza para generar probabilidades predichas tanto en la muestra de entrenamiento como en la de prueba, para evaluar
    su capacidad predictiva y comparar el desempe帽o dentro y fuera de la muestra.'''
    
probit_model = sm.Probit(y_train, X_train_scaled)
probit_results = probit_model.fit(weights=weights_train, disp=True, maxiter=100)
print(probit_results.summary())

y_train_prob = probit_results.predict(X_train_scaled)
y_test_prob = probit_results.predict(X_test_scaled)

#_________________________________________________________________________________________________________________________
# Evaluaci贸n
#_________________________________________________________________________________________________________________________
''' Se calcula el estad铆stico ROC-AUC tanto en la muestra de entrenamiento como en la de prueba, y se compara la diferencia entre ambos valores como criterio
    para detectar sobreajuste; una diferencia peque帽a sugiere que el modelo generaliza adecuadamente fuera de la muestra. Posteriormente, se construye la curva 
    precisionrecall sobre el conjunto de prueba y se calcula el puntaje F1 para distintos umbrales de decisi贸n, seleccionando aquel que maximiza dicho puntaje
    como umbral 贸ptimo de clasificaci贸n. Finalmente, utilizando este umbral, se generan las predicciones binarias, se calcula la matriz de confusi贸n y se presenta
    el reporte de clasificaci贸n, lo que permite evaluar de manera integral la capacidad del modelo para identificar correctamente a los clientes que realizan pagos
    frente a aquellos que no lo hacen, priorizando m茅tricas adecuadas para el problema desbalanceado.'''

roc_auc_train = roc_auc_score(y_train, y_train_prob)
roc_auc_test = roc_auc_score(y_test, y_test_prob)
diferencia = roc_auc_train - roc_auc_test # Dado que es un valor inferior a 0.05, se considera que no hay sobreajuste.

# Umbral
precision, recall, pr_thresholds = precision_recall_curve(y_test, y_test_prob)
f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)
best_threshold_idx = np.argmax(f1_scores)
best_threshold = pr_thresholds[best_threshold_idx] if best_threshold_idx < len(pr_thresholds) else 0.5

# Umbral
y_test_pred = (y_test_prob >= best_threshold).astype(int)
cm = confusion_matrix(y_test, y_test_pred)
reporte_clasificacion = classification_report(y_test, y_test_pred, target_names=['No Paga', 'Paga'], zero_division=0)

''' Los resultados del modelo muestran una capacidad discriminatoria moderada, con valores de ROC-AUC de 0.61 tanto en la muestra de entrenamiento como en la de
    prueba, y una diferencia pr谩cticamente nula entre ambos, lo que indica ausencia de sobreajuste y una adecuada generalizaci贸n fuera de la muestra. El umbral
    贸ptimo de clasificaci贸n, determinado a partir de la maximizaci贸n del puntaje F1, se sit煤a alrededor de 0.14, reflejando el fuerte desbalance de la variable
    objetivo y la necesidad de utilizar un umbral inferior al convencional de 0.5. Bajo este umbral, el modelo logra identificar correctamente el 42 % de los
    clientes que realizan pagos (recall de la clase positiva), aunque con una precisi贸n relativamente baja del 27 %, lo cual es consistente con un enfoque orientado
    a priorizar la detecci贸n de pagadores en un contexto de cobranza. La matriz de confusi贸n confirma este compromiso entre precisi贸n y cobertura, mostrando una
    mejora sustancial en la identificaci贸n de clientes pagadores a costa de un mayor n煤mero de falsos positivos. En conjunto, los resultados sugieren que el modelo
    es 煤til como una herramienta de priorizaci贸n y segmentaci贸n operativa, m谩s que como un clasificador determin铆stico, permitiendo focalizar esfuerzos de cobranza
    en clientes con mayor probabilidad de realizar al menos un pago.'''

#_________________________________________________________________________________________________________________________
# VISUALIZACIONES
#_________________________________________________________________________________________________________________________

fig, axes = plt.subplots(2, 2, figsize=(14, 11))

# 1. Curvas ROC
fpr_train, tpr_train, _ = roc_curve(y_train, y_train_prob)
fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)

axes[0, 0].plot(fpr_train, tpr_train, label=f'Train (AUC={roc_auc_train:.3f})', linewidth=2.5)
axes[0, 0].plot(fpr_test, tpr_test, label=f'Test (AUC={roc_auc_test:.3f})', linewidth=2.5)
axes[0, 0].plot([0,1], [0,1], 'k--', label='Random', alpha=0.5)
axes[0, 0].set_xlabel('False Positive Rate', fontsize=11)
axes[0, 0].set_ylabel('True Positive Rate', fontsize=11)
axes[0, 0].set_title('Curva ROC', fontsize=13, fontweight='bold')
axes[0, 0].legend(fontsize=10)
axes[0, 0].grid(alpha=0.3)

# 2. Distribuci贸n de probabilidades
axes[0, 1].hist(y_test_prob[y_test==0], bins=40, alpha=0.6, label='No Pago', color='salmon', edgecolor='black')
axes[0, 1].hist(y_test_prob[y_test==1], bins=40, alpha=0.6, label='Pago', color='lightgreen', edgecolor='black')
axes[0, 1].axvline(best_threshold, color='red', linestyle='--', linewidth=2.5, label=f'Umbral={best_threshold:.3f}')
axes[0, 1].set_xlabel('Probabilidad Predicha', fontsize=11)
axes[0, 1].set_ylabel('Frecuencia', fontsize=11)
axes[0, 1].set_title('Distribuci贸n de Probabilidades (Test)', fontsize=13, fontweight='bold')
axes[0, 1].legend(fontsize=10)
axes[0, 1].grid(alpha=0.3)

# 3. Precision-Recall Curve
axes[1, 0].plot(recall, precision, linewidth=2.5, color='purple')
axes[1, 0].scatter(recall[best_threshold_idx], precision[best_threshold_idx], 
                   color='red', s=100, zorder=5, label=f'Mejor F1 ({f1_scores[best_threshold_idx]:.3f})')
axes[1, 0].set_xlabel('Recall', fontsize=11)
axes[1, 0].set_ylabel('Precision', fontsize=11)
axes[1, 0].set_title('Curva Precision-Recall', fontsize=13, fontweight='bold')
axes[1, 0].legend(fontsize=10)
axes[1, 0].grid(alpha=0.3)

# 4. Importancia de variables (coeficientes)
coef_df = pd.DataFrame({
    'Variable': probit_results.params.index,
    'Coeficiente': probit_results.params.values,
    'P-valor': probit_results.pvalues.values
})
coef_df = coef_df[coef_df['Variable'] != 'const'].sort_values('Coeficiente', key=abs, ascending=True)

colors = ['green' if x > 0 else 'red' for x in coef_df['Coeficiente']]
axes[1, 1].barh(coef_df['Variable'], coef_df['Coeficiente'], color=colors, alpha=0.7, edgecolor='black')
axes[1, 1].axvline(0, color='black', linewidth=1)
axes[1, 1].set_xlabel('Coeficiente', fontsize=11)
axes[1, 1].set_title('Importancia de Variables', fontsize=13, fontweight='bold')
axes[1, 1].grid(alpha=0.3, axis='x')

plt.tight_layout()
plt.show()

''' Curva ROC.
    La curva ROC muestra un desempe帽o consistente entre las muestras de entrenamiento y prueba, con valores de AUC cercanos a 0.61 en ambos casos. Esto indica que
    el modelo posee una capacidad discriminatoria moderada, superior al azar pero lejos de una separaci贸n perfecta entre clientes pagadores y no pagadores.
    La cercan铆a entre ambas curvas confirma la ausencia de sobreajuste, lo que sugiere que el modelo generaliza adecuadamente fuera de la muestra. 

    Distribuci贸n de probabilidades predichas.
    La distribuci贸n de probabilidades en la muestra de prueba evidencia una superposici贸n considerable entre clientes pagadores y no pagadores, lo cual explica el
    AUC moderado observado. No obstante, se aprecia un desplazamiento hacia la derecha en la distribuci贸n de los clientes que realizan pagos, lo que indica que el
    modelo asigna, en promedio, probabilidades m谩s altas a este grupo. El umbral 贸ptimo seleccionado (0.14), representado por la l铆nea vertical, es coherente con 
    el fuerte desbalance del problema y permite capturar una mayor proporci贸n de pagadores a costa de aceptar m谩s falsos positivos.

    Curva PrecisionRecall.
    La curva PrecisionRecall confirma que el modelo enfrenta un trade-off claro entre precisi贸n y cobertura de la clase positiva. El punto marcado corresponde al
    umbral que maximiza el puntaje F1, con un valor cercano a 0.33, reflejando una mejora sustancial frente a una clasificaci贸n aleatoria en un entorno altamente
    desbalanceado. Este resultado indica que, si bien la precisi贸n para identificar pagadores es limitada, el modelo logra un nivel de recall relevante, lo cual 
    es permite identificar clientes con mayor probabilidad de pago para acciones de cobranza focalizadas.

    Importancia de variables.
    El gr谩fico de coeficientes evidencia que la variable con mayor impacto en la probabilidad de pago es TIPO_CLIENTE_MULTIPRODUCTO, lo que refuerza la
    interpretaci贸n previa de que los clientes con mayor complejidad financiera y m谩s productos presentan una mayor propensi贸n a pagar. Las transformaciones
    logar铆tmicas de saldo y mora, as铆 como sus interacciones, aportan informaci贸n adicional aunque con efectos de menor magnitud. En contraste, variables como
    MORA_EXTREMA y SALDO_ALTO muestran efectos negativos o cercanos a cero, sugiriendo que su contribuci贸n marginal es limitada.'''
    
#_________________________________________________________________________________________________________________________
# An谩lisis de valor 
#_________________________________________________________________________________________________________________________
TN, FP, FN, TP = cm.ravel()
total = TN + FP + FN + TP
costo_contacto = 5000  # COP: costo de contactar a un cliente
ingreso_promedio_pago = df_modelo['SALDO_TOTAL_CLIENTE'].median() * 0.1  # 10% del saldo

print(f'\nSupuestos:')
print(f'  Costo de contactar un cliente: ${costo_contacto:,.0f} COP')
print(f'  Ingreso promedio por pago:     ${ingreso_promedio_pago:,.0f} COP')

valor_TP = ingreso_promedio_pago - costo_contacto  # Contacto exitoso
valor_FP = -costo_contacto  # Contacto sin resultado
valor_TN = 0  # Correcto no contactar
valor_FN = 0  # Oportunidad perdida (pero sin costo directo)

valor_modelo = (TP * valor_TP) + (FP * valor_FP) + (TN * valor_TN) + (FN * valor_FN)

print(f'\n Valor econ贸mico del modelo:')
print(f'  Verdaderos Positivos:  {TP:,}  ${valor_TP:,.0f} = ${TP*valor_TP:,.0f}')
print(f'  Falsos Positivos:      {FP:,}  ${valor_FP:,.0f} = ${FP*valor_FP:,.0f}')
print(f'  Valor neto:                                    ${valor_modelo:,.0f}')

clientes_contactados = TP + FP
tasa_exito = TP / clientes_contactados if clientes_contactados > 0 else 0
print(f'\n Eficiencia operativa:')
print(f'  Clientes a contactar:  {clientes_contactados:,} ({clientes_contactados/total:.1%} del total)')
print(f'  Tasa de 茅xito:         {tasa_exito:.1%}')
print(f'  Pagadores capturados:  {TP:,} de {TP+FN:,} ({TP/(TP+FN):.1%})')

''' A partir de la matriz de confusi贸n, se construye un ejercicio de valoraci贸n econ贸mica bajo supuestos: un costo fijo por contacto y un ingreso promedio esperado
    por pago. Con estos supuestos, se calcula el valor econ贸mico asociado a cada tipo de decisi贸n (verdaderos y falsos positivos), mostrando que el modelo genera un
    valor neto positivo cercano a 71 mil millones de COP al focalizar los contactos en clientes con mayor probabilidad de pago. En este sentido, el aporte principal
    del modelo no es maximizar el ingreso absoluto, sino mejorar la eficiencia, ya que permite contactar solo al 24.7 % de los clientes, capturando el 41.5 % de los
    pagadores, con una tasa de 茅xito del 27.2 %. En conjunto, el an谩lisis muestra que el modelo es especialmente 煤til como herramienta de priorizaci贸n y optimizaci贸n
    de recursos, m谩s que como una regla r铆gida de decisi贸n global.'''
    
#_________________________________________________________________________________________________________________________
# Preguntas
#_________________________________________________________________________________________________________________________

# 驴Por qu茅 un modelo Probir?
''' Se opt贸 por un modelo Probit debido a varias ventajas metodol贸gicas y pr谩cticas. En primer lugar, sus coeficientes admiten una interpretaci贸n econ贸mica clara en
    t茅rminos de efectos sobre la probabilidad de ocurrencia del evento de inter茅s, lo que facilita el an谩lisis y la comunicaci贸n de resultados. Adicionalmente, el
    enfoque Probit permite realizar inferencia estad铆stica formal, incluyendo pruebas de significancia, intervalos de confianza y contrastes de hip贸tesis, aspectos
    fundamentales para validar la robustez del modelo. Asimismo, se trata de un modelo parsimonioso, con un n煤mero reducido de par谩metros, lo que contribuye a la
    estabilidad de las estimaciones y reduce el riesgo de sobreajuste. Finalmente, el modelo Probit es un est谩ndar en la econometr铆a aplicada y es ampliamente
    utilizado en an谩lisis de riesgo crediticio y estudios de comportamiento financiero, lo que respalda su idoneidad para el problema planteado.'''
    
# 驴Alternativas?
''' LightGBM es una alternativa para problemas binarios desbalanceados, ya que se establecio una line base con el modelo Proit, se desarrollara el LightGBM y se
    evaluar su contriuci贸n.'''

#_________________________________________________________________________________________________________________________
# Guardado
#_________________________________________________________________________________________________________________________
modelo_pago = {
    'modelo': probit_results,
    'scaler': scaler,
    'vars_modelo': vars_modelo,
    'threshold': best_threshold,
    'roc_auc_train': roc_auc_train,
    'roc_auc_test': roc_auc_test}

with open(ruta / 'C贸digos/Modelo_1_Posibilidad_pago_Probit_v2.pkl', 'wb') as f:
    pickle.dump(modelo_pago, f)